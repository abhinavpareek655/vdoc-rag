# ğŸ“„ VDoc-RAG (Visually-Rich Document Retrieval-Augmented Generation)

VDoc-RAG is an advanced multimodal system that answers questions from visually-rich documents (PDFs, reports, flyers) by combining OCR, table and chart reasoning, semantic embeddings, and LLMs.

---

## ğŸš€ Features

- ğŸ§  **RAG Pipeline** with persistent ChromaDB  
- ğŸª„ **OCR + Table + Chart understanding**  
- ğŸ“Š **Chart Reasoning** (Pix2Struct + OCR-based)  
- ğŸ” **Environment-based API key handling**  
- ğŸ§® **Confidence Scoring** via cosine similarity  
- ğŸ§¾ **Feedback Loop** for self-improving embeddings  
- ğŸ“ˆ **Benchmark Dashboard** for evaluating embedding models  
- ğŸ’¾ **Persistent Storage** (DuckDB + Parquet backend)

---

## âš™ï¸ Quickstart (Windows)

### 1ï¸âƒ£ Install Dependencies

Install:
- **Tesseract OCR** â†’ [Tesseract Wiki](https://github.com/UB-Mannheim/tesseract/wiki)
- **Poppler for Windows** â†’ [Poppler Releases](https://github.com/oschwartz10612/poppler-windows/releases)

Add both to your system PATH.

### 2ï¸âƒ£ Create Virtual Environment
```bash
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run the App
```bash
uvicorn app.main:app --reload --port 8000
```

Open â†’ [http://127.0.0.1:8000](http://127.0.0.1:8000)

---

## ğŸ–¥ï¸ Web Interfaces

| Page | Route | Description |
|------|-------|--------------|
| `/` | Main Interface | Upload, query, visualize highlights |
| `/feedback_dashboard` | Feedback Loop | View stats, fine-tune model |
| `/benchmark_dashboard` | Benchmarking | Evaluate embeddings (Precision/Recall/MRR) |

---

## ğŸ“ Project Structure

```
vdoc-rag-mvp/
â”œâ”€ app/
â”‚  â”œâ”€ ingest.py              # OCR, table & chart extraction
â”‚  â”œâ”€ chart_reasoner.py      # Chart summarization and trend detection
â”‚  â”œâ”€ indexer.py             # Persistent ChromaDB retrieval
â”‚  â”œâ”€ reader.py              # LLM question answering
â”‚  â”œâ”€ feedback_manager.py    # Feedback collection system
â”‚  â”œâ”€ main.py                # FastAPI server + dashboards
â”‚  â””â”€ visual_highlight.py    # Highlight relevant regions
â”‚
â”œâ”€ models/vdoc_feedback_tuned/  # Fine-tuned embedding model
â”œâ”€ storage/chroma_db/           # Persistent vector store
â”œâ”€ notebooks/evaluate_embeddings.ipynb  # Benchmarking notebook
â””â”€ templates/                   # HTML UIs (main, feedback, benchmark)
```

---

## ğŸ§  Models Used

| Type | Model | Purpose |
|------|--------|----------|
| Embedding | `all-MiniLM-L6-v2` (base), `multi-qa-MiniLM`, feedback-tuned variant | Semantic encoding |
| LLM Reader | Gemini / DistilGPT2 | Context-based answering |
| Chart Reasoning | Pix2Struct / OCR fallback | Visual trend analysis |
| Vector Store | ChromaDB (DuckDB + Parquet) | Persistent retrieval |
| Fine-tuning | SentenceTransformer + CosineLoss | Feedback-based learning |

---

## ğŸ§© Evaluation

- **Confidence Scoring**: cosine similarity between query & chunks  
- **Precision / Recall / MRR**: benchmark dashboards & notebook  
- **Feedback-driven fine-tuning**: iterative model improvement  

---

## ğŸ§  Authorâ€™s Note

VDoc-RAG demonstrates how retrieval-augmented generation can evolve from plain text retrieval into **visually grounded document reasoning**, enabling future systems that can read, reason, and learn continuously.

---

**Developed as a full multimodal RAG research framework** â€” suitable for academic reports, enterprise document intelligence, and AI reasoning pipelines.
